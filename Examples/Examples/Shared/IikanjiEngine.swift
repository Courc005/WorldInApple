//
//  IikanjiEngine.swift
//  WorldInApple
//
//  Created by fuziki on 2020/02/08.
//  Copyright Â© 2020 factory.fuziki. All rights reserved.
//

import Foundation
import AVFoundation
import Accelerate

public class IikanjiEngine {

    private var engine = AVAudioEngine()

    private var player = AVAudioPlayerNode()
    private var reverb = AVAudioUnitReverb()
    private var eq = AVAudioUnitEQ(numberOfBands: 10)
    private var delay = AVAudioUnitDelay()
    private var tapMixer2 = AVAudioMixerNode()

    private var monoMixer = AVAudioMixerNode()
    private var tapMixer = AVAudioMixerNode()
    private var muteMixer = AVAudioMixerNode()

    private var interFormat: AVAudioFormat = AVAudioFormat(commonFormat: .pcmFormatFloat32,
                                                           sampleRate: 44100,
                                                           channels: 1,
                                                           interleaved: false)!
    private var worldFormat: AVAudioFormat = AVAudioFormat(commonFormat: .pcmFormatFloat64,
                                                           sampleRate: 44100,
                                                           channels: 1,
                                                           interleaved: false)!

    private var convTapAudioHandler: ((_ buffer: AVAudioPCMBuffer) -> Void)?
    public func convTapAudio(handler: @escaping (_ buffer: AVAudioPCMBuffer) -> Void) {
        convTapAudioHandler = handler
    }

    private var scheduleAudioHandler: ((_ buffer: [Float]) -> Void)?
    public func scheduleAudio(handler: @escaping (_ buffer: [Float]) -> Void) {
        scheduleAudioHandler = handler
    }

    private var inputConverter: Converter
    private var outputConverter: Converter

    public init() {
        inputConverter = Converter(from: interFormat, to: worldFormat)
        outputConverter = Converter(from: worldFormat, to: interFormat)

        let freqs: [Float] = [31.25, 62.5, 125, 250, 500, 1000, 2000, 4000, 8000, 16000]
        eq.bypass = false
        let eqParams = eq.bands
        for i in 0..<eqParams.count {
            let p = eqParams[i]
            print("p: \(p.bandwidth), \(p.frequency), \(p.filterType.rawValue), \(p.bypass)")
            p.bypass = false
            p.frequency = freqs[i]
            p.filterType = .parametric
            p.bandwidth = 1
        }

        connectNode()
        //        engine.connect(engine.inputNode, to: monoMixer, format: engine.inputNode.outputFormat(forBus: 0))
        //        engine.connect(monoMixer, to: tapMixer, format: interFormat)
        //        engine.connect(tapMixer, to: muteMixer, format: interFormat)
        //        engine.connect(muteMixer, to: engine.mainMixerNode, format: interFormat)
        muteMixer.volume = 0

        engine.inputNode.installTap(onBus: 0,
                                    bufferSize: AVAudioFrameCount(44100 * 0.4),
                                    format: interFormat,
                                    block: { [weak self] (buffer: AVAudioPCMBuffer, _: AVAudioTime) in
                                        self?.onAudio(buffer: buffer)
                                    })

        tapMixer2.installTap(onBus: 0,
                             bufferSize: 4410,
                             format: interFormat,
                             block: { [weak self] (buffer: AVAudioPCMBuffer, _: AVAudioTime) in
                                let arr: [Float] = buffer.audioBufferList.pointee.mBuffers.convertFloatArray()
                                var fftResult: DSPSplitComplex = AccelerateUtil.fft(arr)
                                var fftResult_amplitude = [Float](repeating: 0, count: Int(arr.count / 2))
                                vDSP_zvabs(&fftResult, 1, &fftResult_amplitude, 1, vDSP_Length(arr.count / 2))
                                self?.scheduleAudioHandler?(fftResult_amplitude)
                             })
        engine.prepare()
    }

    public func start() {
        // swiftlint:disable force_try
        try! engine.start()
        player.play()
    }

    private func connectNode() {
        let nodes: [AVAudioNode] = [
            player,
            reverb,
            delay,
            eq,
            tapMixer2,

            monoMixer,
            tapMixer,
            muteMixer
        ]
        for node in nodes {
            engine.attach(node)
        }

        //        reverb.loadFactoryPreset(.mediumRoom)
        //        reverb.wetDryMix = 10

        //        delay.delayTime = 0.3
        //        delay.feedback = 5
        //        delay.lowPassCutoff = 10
        //        delay.wetDryMix = 20

        //        engine.connect(player, to: reverb, format: interFormat)
        //        engine.connect(player, to:tapMixer2, format: interFormat)
        //        engine.connect(tapMixer2, to: engine.mainMixerNode, format: interFormat)
        engine.connect(engine.inputNode, to: monoMixer, format: engine.inputNode.outputFormat(forBus: 0))
        //        engine.connect(monoMixer, to: eq, format: interFormat)
        engine.connect(monoMixer, to: tapMixer, format: interFormat)
        engine.connect(tapMixer, to: muteMixer, format: interFormat)
        engine.connect(muteMixer, to: engine.mainMixerNode, format: interFormat)

        engine.connect(player, to: eq, format: interFormat)
        engine.connect(eq, to: tapMixer2, format: interFormat)
        engine.connect(tapMixer2, to: engine.mainMixerNode, format: interFormat)

    }

    private func onAudio(buffer: AVAudioPCMBuffer) {
        guard let conv = inputConverter.convert(from: buffer) else {
            return
        }
        convTapAudioHandler?(conv)
    }

    public func scheduleBuffer(buffer: AVAudioPCMBuffer) {
        guard let conv = outputConverter.convert(from: buffer) else {
            return
        }

        player.scheduleBuffer(conv, completionHandler: nil)
    }

    public func update(eqValue: [Float]) {
        for i in 0..<min(eqValue.count, eq.bands.count) {
            eq.bands[i].gain = eqValue[i]
        }
    }
}

private class Converter {
    private var converter: AVAudioConverter
    public init(from: AVAudioFormat, to: AVAudioFormat) {
        converter = AVAudioConverter(from: from, to: to)!
    }

    public func convert(from: AVAudioPCMBuffer) -> AVAudioPCMBuffer? {
        let capacity = from.frameCapacity * UInt32(converter.outputFormat.sampleRate / converter.inputFormat.sampleRate)
        guard let to = AVAudioPCMBuffer(pcmFormat: converter.outputFormat, frameCapacity: capacity) else {
            return nil
        }
        var error: NSError?
        converter.convert(to: to,
                          error: &error,
                          withInputFrom: { _, outStatus in
                            outStatus.pointee = AVAudioConverterInputStatus.haveData
                            return from
                          })
        return error == nil ? to : nil
    }
}

extension AudioBuffer {
    public func convertFloatArray() -> [Float] {
        if let mdata: UnsafeMutableRawPointer = self.mData {
            let usmp: UnsafeMutablePointer<Float> = mdata.assumingMemoryBound(to: Float.self)
            // let usp = UnsafeBufferPointer(start: usmp, count: Int(self.mDataByteSize) / MemoryLayout<Float>.size)
            let usp = UnsafeBufferPointer(start: usmp, count: 1024)
            return Array(usp)
        } else {
            return [Float]()
        }
    }
}
